{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# GEO 肿瘤单细胞数据：按步骤下载（metadata + 表达矩阵）\n",
        "\n",
        "这个 Notebook 采用 **“宽进 → MINiML 二次判定 → 只下载矩阵文件”** 的策略，尽量减少漏掉肿瘤单细胞数据集。\n",
        "\n",
        "你会得到：\n",
        "- 候选 GSE 列表（来自 NCBI 官方 E-utilities / db=gds）\n",
        "- 每个候选的 `GSE*_family.xml.tgz`（MINiML metadata）\n",
        "- 本地判定为“像单细胞”的 GSE（带打分与命中关键词）\n",
        "- 只下载 `suppl/` 里“矩阵类”文件（mtx/h5/h5ad/loom/rds/csv/tsv 等）\n",
        "\n",
        "> 注意：RNA-seq 的 raw reads 通常在 SRA（FASTQ），本 Notebook 不下载 raw reads。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0. 安装依赖（只需一次）\n",
        "\n",
        "在终端或 Notebook 里运行（如果你环境已经有，就跳过）："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 如果你是在 Jupyter 里，也可以取消注释这行安装\n",
        "# %pip install -q requests lxml tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. 基本配置：输出目录、NCBI 参数\n",
        "\n",
        "- `OUT_DIR`：你希望保存到哪里\n",
        "- `EMAIL`：建议填真实邮箱（NCBI 更友好）\n",
        "- `NCBI_API_KEY`：可选（有的话速率限制更宽松）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OUT_DIR: /Users/jaxonhe/Projects/BigData/GEO_scData_tumor\n",
            "EMAIL: jiaxinhe@sjtu.edu.cn\n",
            "API_KEY set?: False\n"
          ]
        }
      ],
      "source": [
        "import os, time, re, math\n",
        "from pathlib import Path\n",
        "\n",
        "OUT_DIR = Path.home() / \"Projects\" / \"BigData\" / \"GEO_scData_tumor\"\n",
        "META_DIR = OUT_DIR / \"metadata_miniml\"\n",
        "MATRIX_DIR = OUT_DIR / \"matrices_suppl\"\n",
        "\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "META_DIR.mkdir(parents=True, exist_ok=True)\n",
        "MATRIX_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "EUTILS = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils\"\n",
        "GEO_SERIES_BASE = \"https://ftp.ncbi.nlm.nih.gov/geo/series\"\n",
        "\n",
        "TOOL = \"geo_sc_notebook\"\n",
        "EMAIL = os.getenv(\"NCBI_EMAIL\", \"jiaxinhe@sjtu.edu.cn\")   # 建议改成你真实邮箱\n",
        "NCBI_API_KEY = os.getenv(\"NCBI_API_KEY\", \"\")         # 可选：export NCBI_API_KEY=xxxx\n",
        "\n",
        "print(\"OUT_DIR:\", OUT_DIR)\n",
        "print(\"EMAIL:\", EMAIL)\n",
        "print(\"API_KEY set?:\", bool(NCBI_API_KEY))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. 定义“宽进”的检索式（肿瘤 + 单细胞）\n",
        "\n",
        "你可以自行修改 `QUERY_EXTRA` 来加特定肿瘤类型（比如 glioblastoma、AML、NSCLC 等）。\n",
        "\n",
        "这里我们限定：\n",
        "- `gse[ETYP]`：只要 GSE（Series）\n",
        "- 关键词：肿瘤 + 单细胞（尽量宽，减少漏）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Entrez query: (cancer OR tumor OR tumour OR neoplasm OR carcinoma OR leukemia OR lymphoma OR melanoma OR glioma OR sarcoma OR metastasis) AND (\"single cell\" OR scRNA-seq OR snRNA-seq OR \"single-nucleus\" OR 10x OR Chromium OR Drop-seq OR Smart-seq) AND gse[ETYP]\n"
          ]
        }
      ],
      "source": [
        "TUMOR_PART = \"(cancer OR tumor OR tumour OR neoplasm OR carcinoma OR leukemia OR lymphoma OR melanoma OR glioma OR sarcoma OR metastasis)\"\n",
        "SC_PART = '(\"single cell\" OR scRNA-seq OR snRNA-seq OR \"single-nucleus\" OR 10x OR Chromium OR Drop-seq OR Smart-seq)'\n",
        "\n",
        "QUERY_EXTRA = \"\"   # 例如: 'glioblastoma OR AML OR \"non small cell\"'\n",
        "\n",
        "QUERY = f\"{TUMOR_PART} AND {SC_PART} AND gse[ETYP]\"\n",
        "if QUERY_EXTRA.strip():\n",
        "    QUERY = f\"({QUERY}) AND ({QUERY_EXTRA})\"\n",
        "\n",
        "print(\"Entrez query:\", QUERY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. 用 NCBI E-utilities 搜索（ESearch → UID 列表）\n",
        "\n",
        "这一步只拿到“命中记录的 UID”。下一步用 ESummary 才能拿到 GSE 号。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UID hits: 9384\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['200314072',\n",
              " '200314071',\n",
              " '200311064',\n",
              " '200310392',\n",
              " '200310280',\n",
              " '200303934',\n",
              " '200303451',\n",
              " '200303224',\n",
              " '200295961',\n",
              " '200292490']"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import requests\n",
        "from lxml import etree\n",
        "from tqdm import tqdm\n",
        "\n",
        "session = requests.Session()\n",
        "\n",
        "def eutils_get(endpoint: str, params: dict, timeout=60, max_retries=6):\n",
        "    \"\"\"NCBI E-utilities GET（带 tool/email/api_key + 重试）\"\"\"\n",
        "    params = dict(params)\n",
        "    params[\"tool\"] = TOOL\n",
        "    params[\"email\"] = EMAIL\n",
        "    if NCBI_API_KEY:\n",
        "        params[\"api_key\"] = NCBI_API_KEY\n",
        "\n",
        "    url = f\"{EUTILS}/{endpoint}\"\n",
        "    backoff = 1.8\n",
        "    for i in range(max_retries):\n",
        "        r = session.get(url, params=params, timeout=timeout)\n",
        "        if r.status_code == 200:\n",
        "            return r.text\n",
        "        if r.status_code in (429, 500, 502, 503, 504):\n",
        "            time.sleep(backoff ** i)\n",
        "            continue\n",
        "        r.raise_for_status()\n",
        "    raise RuntimeError(f\"Failed after retries: {url}\")\n",
        "\n",
        "def polite_sleep():\n",
        "    time.sleep(0.12 if NCBI_API_KEY else 0.35)\n",
        "\n",
        "def esearch_gds(term: str, retmax=50000):\n",
        "    xml = eutils_get(\"esearch.fcgi\", {\n",
        "        \"db\": \"gds\",\n",
        "        \"term\": term,\n",
        "        \"retmax\": str(retmax),\n",
        "        \"retmode\": \"xml\"\n",
        "    })\n",
        "    root = etree.fromstring(xml.encode(\"utf-8\"))\n",
        "    return root.xpath(\"//IdList/Id/text()\")\n",
        "\n",
        "uids = esearch_gds(QUERY, retmax=50000)\n",
        "print(\"UID hits:\", len(uids))\n",
        "uids[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. 用 ESummary 把 UID 转成 GSE 列表（Accession + Title）\n",
        "\n",
        "我们会：\n",
        "- 分批（batch）拉取\n",
        "- 只保留 Accession 以 `GSE` 开头的记录\n",
        "- 保存为 `candidates_gse.tsv`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ESummary batches: 100%|██████████| 94/94 [01:56<00:00,  1.24s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Candidate GSE: 9384\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[('GSE314072',\n",
              "  'Functionally heterogeneous intratumoral CD4+CD8+ double positive T cells can give rise to single positive T cells [scRNA-seq + scTCR-seq]'),\n",
              " ('GSE314071',\n",
              "  'Functionally heterogeneous intratumoral CD4+CD8+ double positive T cells can give rise to single positive T cells [bulkRNA-seq]'),\n",
              " ('GSE311064',\n",
              "  'Cellular senescence in human liver under normal aging and cancer'),\n",
              " ('GSE310392',\n",
              "  'Cellular senescence in human liver under normal aging and cancer [Xenium]'),\n",
              " ('GSE310280',\n",
              "  'Single cell sequencing of Stellate Ganglion of mice retrolabeled from interscapular brown adipose tissue and forelimb')]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def esummary_gds(uids, batch=100):\n",
        "    rows = []\n",
        "    for i in tqdm(range(0, len(uids), batch), desc=\"ESummary batches\"):\n",
        "        chunk = uids[i:i+batch]\n",
        "        xml = eutils_get(\"esummary.fcgi\", {\n",
        "            \"db\": \"gds\",\n",
        "            \"id\": \",\".join(chunk),\n",
        "            \"retmode\": \"xml\"\n",
        "        }, timeout=90)\n",
        "        root = etree.fromstring(xml.encode(\"utf-8\"))\n",
        "        for doc in root.xpath(\"//DocSum\"):\n",
        "            acc = \"\".join(doc.xpath(\"./Item[@Name='Accession']/text()\")).strip()\n",
        "            title = \"\".join(doc.xpath(\"./Item[@Name='title']/text()\")).strip()\n",
        "            if acc.startswith(\"GSE\"):\n",
        "                rows.append((acc, title))\n",
        "        polite_sleep()\n",
        "    return rows\n",
        "\n",
        "rows = esummary_gds(uids)\n",
        "# 去重\n",
        "seen = set()\n",
        "gse_list = []\n",
        "for acc, title in rows:\n",
        "    if acc not in seen:\n",
        "        seen.add(acc)\n",
        "        gse_list.append((acc, title))\n",
        "\n",
        "print(\"Candidate GSE:\", len(gse_list))\n",
        "gse_list[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 保存候选列表\n",
        "cand_path = OUT_DIR / \"candidates_gse.tsv\"\n",
        "with cand_path.open(\"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(\"GSE\\tTitle\\n\")\n",
        "    for acc, title in gse_list:\n",
        "        f.write(f\"{acc}\\t{title}\\n\")\n",
        "\n",
        "print(\"Saved:\", cand_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. 生成每个 GSE 的 MINiML / suppl URL\n",
        "\n",
        "GEO 的 series 目录使用“千位分桶”规则：\n",
        "- `GSE20329` → `.../series/GSE20nnn/GSE20329/...`\n",
        "\n",
        "我们先构造：\n",
        "- `MINiML family`：metadata\n",
        "- `suppl/`：矩阵文件通常在这里\n",
        "- （可选）`SeriesMatrix`：单细胞不一定有，但也能试试"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def bucket_for_gse(acc: str) -> str:\n",
        "    n = int(acc[3:])\n",
        "    return f\"GSE{n//1000}nnn\"\n",
        "\n",
        "def gse_root(acc: str) -> str:\n",
        "    return f\"{GEO_SERIES_BASE}/{bucket_for_gse(acc)}/{acc}\"\n",
        "\n",
        "def gse_urls(acc: str) -> dict:\n",
        "    root = gse_root(acc)\n",
        "    return {\n",
        "        \"miniml_family\": f\"{root}/miniml/{acc}_family.xml.tgz\",\n",
        "        \"suppl_dir\": f\"{root}/suppl/\",\n",
        "        \"series_matrix\": f\"{root}/matrix/{acc}_series_matrix.txt.gz\",\n",
        "        \"raw_tar\": f\"{root}/suppl/{acc}_RAW.tar\",\n",
        "    }\n",
        "\n",
        "# 看看一个例子\n",
        "example = gse_list[0][0]\n",
        "example, gse_urls(example)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. 下载 MINiML（metadata）并做“单细胞打分”\n",
        "\n",
        "### 为什么要打分？\n",
        "因为 GEO 的标注不统一，单靠检索式容易漏。我们下载 MINiML 后在本地扫描一些“单细胞强信号”关键词。\n",
        "\n",
        "你可以调 `MIN_SCORE`：\n",
        "- 更低：更不容易漏，但会混入更多 bulk，需要你再人工扫一眼\n",
        "- 更高：更干净，但可能漏一些写得含糊的项目"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tarfile\n",
        "\n",
        "SC_KEYWORDS = [\n",
        "    \"single cell\", \"single-cell\", \"scrna\", \"scrna-seq\", \"snrna\", \"snrna-seq\",\n",
        "    \"single nucleus\", \"single-nucleus\", \"10x\", \"chromium\", \"drop-seq\", \"smart-seq\",\n",
        "    \"umi\", \"cell barcode\", \"barcodes\", \"droplet\", \"microwell\"\n",
        "]\n",
        "\n",
        "MIN_SCORE = 2   # 推荐 2（更保守不漏）；如果太多误报可调到 3\n",
        "\n",
        "def download_with_resume(url: str, out_path: Path, timeout=180):\n",
        "    \"\"\"HTTP Range 断点续传；返回 OK/404/FAIL\"\"\"\n",
        "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "    for attempt in range(6):\n",
        "        try:\n",
        "            headers = {}\n",
        "            mode = \"wb\"\n",
        "            existing = out_path.stat().st_size if out_path.exists() else 0\n",
        "            if existing > 0:\n",
        "                headers[\"Range\"] = f\"bytes={existing}-\"\n",
        "                mode = \"ab\"\n",
        "\n",
        "            with session.get(url, stream=True, timeout=timeout, headers=headers) as r:\n",
        "                if r.status_code == 404:\n",
        "                    return \"404\"\n",
        "                r.raise_for_status()\n",
        "                # Range 不被支持时，服务器可能返回 200，重新从头下更安全\n",
        "                if \"Range\" in headers and r.status_code == 200:\n",
        "                    mode = \"wb\"\n",
        "                with out_path.open(mode, \"ab\" if mode==\"ab\" else \"wb\") as f:\n",
        "                    for chunk in r.iter_content(chunk_size=1024*1024):\n",
        "                        if chunk:\n",
        "                            f.write(chunk)\n",
        "            return \"OK\"\n",
        "        except Exception:\n",
        "            time.sleep(1.8 ** attempt)\n",
        "    return \"FAIL\"\n",
        "\n",
        "def extract_xml_from_tgz(tgz_path: Path):\n",
        "    \"\"\"从 .xml.tgz 中取出第一个 .xml 文件内容（bytes）\"\"\"\n",
        "    try:\n",
        "        with tarfile.open(tgz_path, \"r:gz\") as tf:\n",
        "            for m in tf.getmembers():\n",
        "                if m.isfile() and m.name.lower().endswith(\".xml\"):\n",
        "                    f = tf.extractfile(m)\n",
        "                    if f:\n",
        "                        return f.read()\n",
        "    except Exception:\n",
        "        return None\n",
        "    return None\n",
        "\n",
        "def xml_to_text_lower(xml_bytes: bytes) -> str:\n",
        "    try:\n",
        "        root = etree.fromstring(xml_bytes)\n",
        "        text = \" \".join(root.xpath(\"//text()\"))\n",
        "        return re.sub(r\"\\s+\", \" \", text).lower()\n",
        "    except Exception:\n",
        "        return \"\"\n",
        "\n",
        "def sc_score(text_lc: str):\n",
        "    score = 0\n",
        "    matched = []\n",
        "    for kw in SC_KEYWORDS:\n",
        "        if kw in text_lc:\n",
        "            matched.append(kw)\n",
        "            if kw in (\"single cell\", \"single-cell\", \"scrna-seq\", \"snrna-seq\"):\n",
        "                score += 3\n",
        "            elif kw in (\"umi\", \"cell barcode\", \"barcodes\", \"droplet\"):\n",
        "                score += 2\n",
        "            else:\n",
        "                score += 1\n",
        "    return score, matched"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 为了先跑通，建议先在小样本上测试，比如前 50 个\n",
        "TEST_N = min(50, len(gse_list))\n",
        "to_check = [acc for acc, _ in gse_list[:TEST_N]]\n",
        "\n",
        "accepted = []\n",
        "rejected = []\n",
        "\n",
        "for acc in tqdm(to_check, desc=\"MINiML download+score\"):\n",
        "    urls = gse_urls(acc)\n",
        "    tgz_path = META_DIR / acc / f\"{acc}_family.xml.tgz\"\n",
        "    st = download_with_resume(urls[\"miniml_family\"], tgz_path)\n",
        "    if st != \"OK\":\n",
        "        rejected.append((acc, -1, st))\n",
        "        continue\n",
        "\n",
        "    xml_bytes = extract_xml_from_tgz(tgz_path)\n",
        "    if not xml_bytes:\n",
        "        rejected.append((acc, -1, \"no_xml\"))\n",
        "        continue\n",
        "\n",
        "    text_lc = xml_to_text_lower(xml_bytes)\n",
        "    score, matched = sc_score(text_lc)\n",
        "\n",
        "    if score >= MIN_SCORE:\n",
        "        accepted.append((acc, score, matched))\n",
        "    else:\n",
        "        rejected.append((acc, score, \"low_score\"))\n",
        "\n",
        "len(accepted), len(rejected), accepted[:3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "把测试跑通后，你可以把 `TEST_N` 改成全量（`len(gse_list)`），并把结果写到文件。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 保存测试阶段的结果\n",
        "acc_path = OUT_DIR / \"accepted_singlecell_TEST.tsv\"\n",
        "rej_path = OUT_DIR / \"rejected_TEST.tsv\"\n",
        "\n",
        "with acc_path.open(\"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(\"GSE\\tScore\\tMatchedKeywords\\n\")\n",
        "    for acc, score, matched in sorted(accepted, key=lambda x: (-x[1], x[0])):\n",
        "        f.write(f\"{acc}\\t{score}\\t{';'.join(matched)}\\n\")\n",
        "\n",
        "with rej_path.open(\"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(\"GSE\\tScore\\tReason\\n\")\n",
        "    for acc, score, reason in rejected:\n",
        "        f.write(f\"{acc}\\t{score}\\t{reason}\\n\")\n",
        "\n",
        "print(\"Saved:\", acc_path)\n",
        "print(\"Saved:\", rej_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. 对“判定为单细胞”的 GSE：只下载 suppl 里矩阵类文件\n",
        "\n",
        "这里我们做两件事：\n",
        "1) 访问 `.../suppl/` 的目录 listing（HTML）拿到文件名\n",
        "2) 用白名单规则只下载矩阵文件（mtx/h5/h5ad/loom/rds/csv/tsv/txt 等）\n",
        "\n",
        "> 这一步不会下载 SRA raw reads。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from lxml import html as lxml_html\n",
        "\n",
        "MATRIX_PATTERNS = [\n",
        "    r\"(matrix\\.mtx(\\.gz)?)$\",\n",
        "    r\"(barcodes\\.tsv(\\.gz)?)$\",\n",
        "    r\"(features\\.tsv(\\.gz)?)$\",\n",
        "    r\"(genes\\.tsv(\\.gz)?)$\",\n",
        "    r\"(\\.h5ad)$\",\n",
        "    r\"(\\.loom)$\",\n",
        "    r\"(\\.h5)$\",\n",
        "    r\"(\\.rds)$\",\n",
        "    r\"(\\.rda)$\",\n",
        "    r\"(count|counts|umi|expression|matrix).*?\\.(csv|tsv|txt)(\\.gz)?$\",\n",
        "]\n",
        "\n",
        "def list_suppl_files(suppl_url: str):\n",
        "    r = session.get(suppl_url, timeout=60)\n",
        "    if r.status_code == 404:\n",
        "        return []\n",
        "    r.raise_for_status()\n",
        "    doc = lxml_html.fromstring(r.text)\n",
        "    hrefs = doc.xpath(\"//a/@href\")\n",
        "    files = []\n",
        "    for h in hrefs:\n",
        "        h = h.strip()\n",
        "        if not h or h.endswith(\"/\") or h in (\".\", \"..\", \"../\"):\n",
        "            continue\n",
        "        files.append(h)\n",
        "    # 去重\n",
        "    out, seen = [], set()\n",
        "    for f in files:\n",
        "        if f not in seen:\n",
        "            seen.add(f)\n",
        "            out.append(f)\n",
        "    return out\n",
        "\n",
        "def is_matrix_file(fn: str) -> bool:\n",
        "    fn_l = fn.lower()\n",
        "    return any(re.search(p, fn_l) for p in MATRIX_PATTERNS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 先对一个 GSE 试试（取第一个 accepted）\n",
        "if not accepted:\n",
        "    raise RuntimeError(\"No accepted GSE in test run; lower MIN_SCORE or increase TEST_N.\")\n",
        "\n",
        "acc0 = accepted[0][0]\n",
        "urls0 = gse_urls(acc0)\n",
        "files0 = list_suppl_files(urls0[\"suppl_dir\"])\n",
        "\n",
        "print(\"Example accepted GSE:\", acc0)\n",
        "print(\"Suppl files (first 30):\")\n",
        "print(files0[:30])\n",
        "\n",
        "matrix_like = [f for f in files0 if is_matrix_file(f)]\n",
        "print(\"\\nMatrix-like files:\")\n",
        "print(matrix_like[:30])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "如果 `matrix_like` 是空的，常见原因：\n",
        "- 作者把矩阵打进了 `GSE*_RAW.tar`\n",
        "- 或者矩阵在更深的子目录/其它链接（GEO listing 不一定直接列出）\n",
        "\n",
        "你可以选择：\n",
        "- 只下载 `GSE*_RAW.tar`，然后在本地解包提取 10x 三件套\n",
        "- 或者把白名单放宽（例如下载所有 `.gz` 然后再筛）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 下载该 GSE 的 matrix-like 文件（示例：只下载这个 acc0）\n",
        "jobs = []\n",
        "for fn in matrix_like:\n",
        "    url = urls0[\"suppl_dir\"] + fn\n",
        "    out = MATRIX_DIR / acc0 / fn\n",
        "    jobs.append((url, out))\n",
        "\n",
        "print(\"Jobs:\", len(jobs))\n",
        "jobs[:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 执行下载（示例：单线程，便于你观察）\n",
        "ok = fail = skip404 = 0\n",
        "for url, out in tqdm(jobs, desc=\"download matrix-like files\"):\n",
        "    st = download_with_resume(url, out, timeout=240)\n",
        "    if st == \"OK\":\n",
        "        ok += 1\n",
        "    elif st == \"404\":\n",
        "        skip404 += 1\n",
        "    else:\n",
        "        fail += 1\n",
        "\n",
        "print(\"OK:\", ok, \"404:\", skip404, \"FAIL:\", fail)\n",
        "print(\"Saved under:\", MATRIX_DIR / acc0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. 扩展到批量：把 accepted 列表都跑一遍\n",
        "\n",
        "把下面 cell 里的 `accepted` 换成你全量跑出来的 accepted（不是 TEST）。\n",
        "\n",
        "建议：\n",
        "- 并发下载可以用 `ThreadPoolExecutor`（文件多时更快）\n",
        "- 但别开太大并发（4~8 够了）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "\n",
        "def download_jobs_for_gse(acc: str):\n",
        "    urls = gse_urls(acc)\n",
        "    try:\n",
        "        files = list_suppl_files(urls[\"suppl_dir\"])\n",
        "    except Exception:\n",
        "        files = []\n",
        "    matrix_like = [f for f in files if is_matrix_file(f)]\n",
        "    jobs = [(urls[\"suppl_dir\"] + fn, MATRIX_DIR / acc / fn) for fn in matrix_like]\n",
        "    return jobs\n",
        "\n",
        "# 这里用测试阶段的 accepted 演示\n",
        "all_jobs = []\n",
        "for acc, score, matched in accepted:\n",
        "    all_jobs.extend(download_jobs_for_gse(acc))\n",
        "\n",
        "print(\"Total matrix-like download jobs:\", len(all_jobs))\n",
        "\n",
        "# 并发下载\n",
        "workers = 4\n",
        "ok = fail = skip404 = 0\n",
        "with ThreadPoolExecutor(max_workers=workers) as ex:\n",
        "    futs = [ex.submit(download_with_resume, url, out, 240) for url, out in all_jobs]\n",
        "    for fut in tqdm(as_completed(futs), total=len(futs), desc=\"FILES\"):\n",
        "        st = fut.result()\n",
        "        if st == \"OK\":\n",
        "            ok += 1\n",
        "        elif st == \"404\":\n",
        "            skip404 += 1\n",
        "        else:\n",
        "            fail += 1\n",
        "\n",
        "print(\"OK:\", ok, \"404:\", skip404, \"FAIL:\", fail)\n",
        "print(\"Matrices saved under:\", MATRIX_DIR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. 下一步（你跑通后再做）\n",
        "\n",
        "- 把 `TEST_N` 改成全量：`TEST_N = len(gse_list)`\n",
        "- 如果漏得多：降低 `MIN_SCORE` 或增加 `SC_KEYWORDS`\n",
        "- 如果误报多：提高 `MIN_SCORE` 或加入更强信号（比如 UMI/barcode 的权重）\n",
        "- 如果很多 GSE 的矩阵只在 `RAW.tar`：我们可以加一个 cell **自动下载 RAW.tar 并只解包 10x 三件套/对象文件**（避免解出一堆无关文件）\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
